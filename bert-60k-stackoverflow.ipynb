{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install contractions\n!pip install evaluate\n!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n\nimport pandas as pd\nimport contractions\nimport re\nimport spacy\nimport warnings\nimport torch\nimport numpy as np\nimport os\nimport datasets\n\nfrom datasets import Dataset, DatasetDict\nfrom transformers import get_scheduler\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nfrom bs4 import BeautifulSoup\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom torch.utils.data import DataLoader\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nnlp = spacy.load(\"en_core_web_sm\")\nstopwords = nlp.Defaults.stop_words\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\npd.set_option('display.max_colwidth', 400)\n\nos.makedirs(\"/kaggle/model\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-15T22:04:45.911989Z","iopub.execute_input":"2023-01-15T22:04:45.913005Z","iopub.status.idle":"2023-01-15T22:05:15.119325Z","shell.execute_reply.started":"2023-01-15T22:04:45.912891Z","shell.execute_reply":"2023-01-15T22:05:15.118138Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: contractions in /opt/conda/lib/python3.7/site-packages (0.1.73)\nRequirement already satisfied: textsearch>=0.0.21 in /opt/conda/lib/python3.7/site-packages (from contractions) (0.0.24)\nRequirement already satisfied: pyahocorasick in /opt/conda/lib/python3.7/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\nRequirement already satisfied: anyascii in /opt/conda/lib/python3.7/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.13.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2022.11.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.10.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (22.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.13)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mjupyter_http_over_ws extension initialized. Listening on /http_over_websocket\n\u001b[32m[I 22:05:07.244 NotebookApp]\u001b[m Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n\u001b[35m[C 22:05:09.103 NotebookApp]\u001b[m Running as root is not recommended. Use --allow-root to bypass.\n/kaggle/input/60k-stack-overflow-questions-with-quality-rate/valid.csv\n/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased' , num_labels=3)\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\" , num_labels=3);","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:05:22.383077Z","iopub.execute_input":"2023-01-15T22:05:22.383900Z","iopub.status.idle":"2023-01-15T22:05:43.494300Z","shell.execute_reply.started":"2023-01-15T22:05:22.383859Z","shell.execute_reply":"2023-01-15T22:05:43.493237Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bd7b148605e48eeb6628f16468064e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbcab11a9440403baf8a8efe4f91141a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"939ecc51db9246838c5c9b636205a050"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595fc812ffa0432fb6187e7783fc7f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d8b01c00704046af72e44ef13f9045"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:05:43.496673Z","iopub.execute_input":"2023-01-15T22:05:43.497481Z","iopub.status.idle":"2023-01-15T22:05:43.513013Z","shell.execute_reply.started":"2023-01-15T22:05:43.497435Z","shell.execute_reply":"2023-01-15T22:05:43.511715Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv')\ndf_valid = pd.read_csv('/kaggle/input/60k-stack-overflow-questions-with-quality-rate/valid.csv')\n\ndf_train = df_train.filter({'Title' , 'Body' , 'Tags' , 'Y'})\ndf_train['Y'] = df_train['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT': 1, 'HQ':2})\n\ndf_valid = df_valid.filter({'Title' , 'Body' , 'Tags' , 'Y'})\ndf_valid['Y'] = df_valid['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT': 1, 'HQ':2})","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:05:43.514746Z","iopub.execute_input":"2023-01-15T22:05:43.515435Z","iopub.status.idle":"2023-01-15T22:05:45.248916Z","shell.execute_reply.started":"2023-01-15T22:05:43.515388Z","shell.execute_reply":"2023-01-15T22:05:45.247878Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Preprocessing:\n    def __get_tag_col(self , text):\n        text = text.replace('<' , ' ')\n        text = text.replace('>' , ' ')\n        text = text.split()\n        text = ' '.join(text)\n        return text.split()\n\n    def __get_body_tag_text(self , text):\n        soup = BeautifulSoup(text ,features='xml')\n        return soup.get_text()\n    \n    def __handle_contractions(self , text):\n        c = []\n        for word in text.split():\n            c.append(contractions.fix(word)) \n        c = ' '.join(c)\n        return c\n\n    def __get_ents(self , text):\n        remove_ent = ['CARDINAL' , 'PERSON' , 'TIME' , 'DATE']\n        doc = nlp(text)\n        ent_list = []\n\n        for t in doc.ents:\n            if t.label_ not in remove_ent:\n                ent_list.append((t.text , t.label_))\n                \n        return ent_list\n        \n    def __lower_and_punc_removal(self , text):\n        text = text.lower()\n        text = re.sub(r'[^(a-zA-Z)\\s]','', text)\n        return text\n\n    def __init__(self , df):\n        self.df = df\n        self.df['Tags_list'] = self.df['Tags'].apply(self.__get_tag_col) # treat as entities\n        self.tag_list = []\n        for tags in self.df['Tags_list']:\n            for e in tags:\n                self.tag_list.append(e)\n        self.tag_list = pd.Series(self.tag_list)\n        self.df['Body_Between_Tags'] = self.df['Body'].apply(self.__get_body_tag_text)\n        self.df['Body_ENTS'] = self.df['Body_Between_Tags'].apply(self.__get_ents)\n        self.df['Title_ENTS'] = self.df['Title'].apply(self.__get_ents)\n        self.df['Body_Text_Cleaned'] = self.df['Body_Between_Tags'].apply(self.__handle_contractions)\n        self.df['Final_clean'] = self.df['Body_Between_Tags'].apply(self.__lower_and_punc_removal)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:05:45.251507Z","iopub.execute_input":"2023-01-15T22:05:45.251904Z","iopub.status.idle":"2023-01-15T22:05:45.265097Z","shell.execute_reply.started":"2023-01-15T22:05:45.251869Z","shell.execute_reply":"2023-01-15T22:05:45.263721Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"PreprocessedObject_train = Preprocessing(df=df_train)\nPreprocessedObject_valid = Preprocessing(df=df_valid)\n\nPreprocessedObject_train.df.dropna(inplace=True)\nPreprocessedObject_valid.df.dropna(inplace=True)\nPreprocessedObject_train.df.reset_index(inplace=True)\nPreprocessedObject_valid.df.reset_index(inplace=True)\n\ndf_train_final = PreprocessedObject_train.df\ndf_valid_final = PreprocessedObject_valid.df","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:05:45.266574Z","iopub.execute_input":"2023-01-15T22:05:45.267152Z","iopub.status.idle":"2023-01-15T22:19:34.411299Z","shell.execute_reply.started":"2023-01-15T22:05:45.267105Z","shell.execute_reply":"2023-01-15T22:19:34.410215Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train_final.drop(['index' , 'Tags', 'Body', 'Title', 'Tags_list', 'Body_Between_Tags', 'Body_ENTS', 'Title_ENTS', 'Body_Text_Cleaned'] , inplace=True , axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:19:34.412621Z","iopub.execute_input":"2023-01-15T22:19:34.412993Z","iopub.status.idle":"2023-01-15T22:19:34.444163Z","shell.execute_reply.started":"2023-01-15T22:19:34.412959Z","shell.execute_reply":"2023-01-15T22:19:34.443206Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_valid_final.drop(['index' , 'Tags', 'Body', 'Title', 'Tags_list', 'Body_Between_Tags', 'Body_ENTS', 'Title_ENTS', 'Body_Text_Cleaned'], inplace=True , axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:19:34.445925Z","iopub.execute_input":"2023-01-15T22:19:34.446286Z","iopub.status.idle":"2023-01-15T22:19:34.461193Z","shell.execute_reply.started":"2023-01-15T22:19:34.446251Z","shell.execute_reply":"2023-01-15T22:19:34.460313Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"datasets_train_test = DatasetDict({\n    \"train\": Dataset.from_pandas(df_train_final),\n    \"test\": Dataset.from_pandas(df_valid_final)\n    })","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:19:34.462865Z","iopub.execute_input":"2023-01-15T22:19:34.463205Z","iopub.status.idle":"2023-01-15T22:19:34.504704Z","shell.execute_reply.started":"2023-01-15T22:19:34.463171Z","shell.execute_reply":"2023-01-15T22:19:34.503861Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"Final_clean\"], padding=\"max_length\", truncation=True)\ntokenized_datasets = datasets_train_test.map(tokenize_function, batched=True)\n\ntokenized_datasets = tokenized_datasets.remove_columns(['Final_clean'])\ntokenized_datasets = tokenized_datasets.rename_column(\"Y\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\n\ntrain_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=8)\neval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:19:34.505935Z","iopub.execute_input":"2023-01-15T22:19:34.506265Z","iopub.status.idle":"2023-01-15T22:19:54.998877Z","shell.execute_reply.started":"2023-01-15T22:19:34.506228Z","shell.execute_reply":"2023-01-15T22:19:54.997864Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6c0229b15a45fe979f5a2e7e021cdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20dc8436357e4775be4756b9e40034ad"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:19:55.002476Z","iopub.execute_input":"2023-01-15T22:19:55.002874Z","iopub.status.idle":"2023-01-15T22:19:55.010041Z","shell.execute_reply.started":"2023-01-15T22:19:55.002843Z","shell.execute_reply":"2023-01-15T22:19:55.008725Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 45000\n    })\n    test: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 15000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5)\nnum_epochs = 1\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\n\nmodel.train()\nfor epoch in range(num_epochs):\n    print('Epoch ' , epoch + 1 , '/' , num_epochs)\n    for batch in tqdm(train_dataloader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        \n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-01-15T22:19:55.012013Z","iopub.execute_input":"2023-01-15T22:19:55.012511Z","iopub.status.idle":"2023-01-15T23:30:09.651961Z","shell.execute_reply.started":"2023-01-15T22:19:55.012473Z","shell.execute_reply":"2023-01-15T23:30:09.650848Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch  1 / 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5625/5625 [1:10:05<00:00,  1.34it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"accuracy\")\nmodel.eval()\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2023-01-15T23:30:09.653557Z","iopub.execute_input":"2023-01-15T23:30:09.653947Z","iopub.status.idle":"2023-01-15T23:38:59.764332Z","shell.execute_reply.started":"2023-01-15T23:30:09.653909Z","shell.execute_reply":"2023-01-15T23:38:59.763383Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d868ffb88c9a4968a2e03300aaf335f0"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8750666666666667}"},"metadata":{}}]}]}