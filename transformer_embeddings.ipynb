{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fae9a4c-6e27-47cb-aa84-e04bca22a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import TransformerEncoderLayer , TransformerDecoderLayer, CosineSimilarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc3ae7-ce40-4743-996f-0cc36327e8de",
   "metadata": {},
   "source": [
    "## Simple encoder-decoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061d76e9-8cac-474f-b419-eabc593f6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "t1 = torch.Tensor([[[1 , 47 , 3]]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb84299-fa33-44d8-8853-df6fa81273c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerEncoderLayer(\n",
      "  (self_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=3, out_features=2048, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (linear2): Linear(in_features=2048, out_features=3, bias=True)\n",
      "  (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout1): Dropout(p=0, inplace=False)\n",
      "  (dropout2): Dropout(p=0, inplace=False)\n",
      ")\n",
      "tensor([[[-1.0854,  1.3278, -0.2424]]])\n"
     ]
    }
   ],
   "source": [
    "# encoder_layer contains feedforward layer with bias b\n",
    "encoder_layer = TransformerEncoderLayer(d_model=3, nhead=1, dropout=0).to(device)\n",
    "print(encoder_layer)\n",
    "e1 = encoder_layer(t1).detach()\n",
    "print(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7de23d-f24d-4c77-a151-829077f75f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDecoderLayer(\n",
      "  (self_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "  )\n",
      "  (multihead_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=3, out_features=2048, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (linear2): Linear(in_features=2048, out_features=3, bias=True)\n",
      "  (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout1): Dropout(p=0, inplace=False)\n",
      "  (dropout2): Dropout(p=0, inplace=False)\n",
      "  (dropout3): Dropout(p=0, inplace=False)\n",
      ")\n",
      "tensor([[[-1.3851,  0.9397,  0.4454]]])\n"
     ]
    }
   ],
   "source": [
    "# decoder_layer contains feedforward layer with bias b\n",
    "decoder_layer = TransformerDecoderLayer(d_model=3 , nhead=1 , dropout=0).to(device)\n",
    "print(decoder_layer)\n",
    "\n",
    "# decode e1\n",
    "d1 = decoder_layer(e1 , e1)\n",
    "d1 = d1.detach()\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dedd31-b1eb-44dc-b7b2-5e15e8c75431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
