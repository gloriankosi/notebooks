{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/gke/kosig/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: dill in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (0.11.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: pandas in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (1.23.3)\n",
      "Requirement already satisfied: packaging in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: xxhash in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/gke/kosig/lib/python3.9/site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/gke/kosig/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/gke/kosig/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/gke/kosig/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gke/kosig/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: filelock in /Users/gke/kosig/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/gke/kosig/lib/python3.9/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gke/kosig/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.6.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gke/kosig/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/gke/kosig/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gke/kosig/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gke/kosig/lib/python3.9/site-packages (from pandas->evaluate) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/gke/kosig/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gke/kosig/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/gke/kosig/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gke/kosig/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/gke/kosig/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gke/kosig/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/gke/kosig/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gke/kosig/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: rouge_score in /Users/gke/kosig/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /Users/gke/kosig/lib/python3.9/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/gke/kosig/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Users/gke/kosig/lib/python3.9/site-packages (from rouge_score) (1.23.3)\n",
      "Requirement already satisfied: absl-py in /Users/gke/kosig/lib/python3.9/site-packages (from rouge_score) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/gke/kosig/lib/python3.9/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in /Users/gke/kosig/lib/python3.9/site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/gke/kosig/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gke/kosig/lib/python3.9/site-packages (from nltk->rouge_score) (2022.8.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer , pipeline\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Base BART\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870521, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(),'data/new_summarization_data.csv'))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f49ee725a0360aa6881ed1f7999cc531885dd06a</td>\n",
       "      <td>New York police are concerned drones could bec...</td>\n",
       "      <td>Police have investigated criminals who have ri...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        ID  \\\n",
       "0           0  f49ee725a0360aa6881ed1f7999cc531885dd06a   \n",
       "\n",
       "                                             Content  \\\n",
       "0  New York police are concerned drones could bec...   \n",
       "\n",
       "                                             Summary         Dataset  \n",
       "0  Police have investigated criminals who have ri...  CNN/Daily Mail  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "df_1 = df.drop(columns={'Unnamed: 0' , 'ID' , 'Dataset'}, axis=1)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True).input_ids\n",
    "\n",
    "df_train = df_1.sample(frac=0.8,random_state=12)\n",
    "df_test = df_1.drop(df_train.index)\n",
    "\n",
    "train = pd.DataFrame(index=None)\n",
    "\n",
    "train['input_ids'] = df_train['Content'].apply(tokenize_function)\n",
    "train['labels'] = df_train['Summary'].apply(tokenize_function)\n",
    "\n",
    "test = pd.DataFrame(index=None)\n",
    "\n",
    "test['input_ids'] = df_test['Content'].apply(tokenize_function)\n",
    "test['labels'] = df_test['Summary'].apply(tokenize_function)\n",
    "\n",
    "datasets_train_test = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train),\n",
    "    \"test\": Dataset.from_pandas(test)\n",
    "    })\n",
    "\n",
    "datasets_train_test = datasets_train_test.remove_columns(['__index_level_0__'])\n",
    "\n",
    "datasets_train_test.set_format('torch')\n",
    "\n",
    "train_dataloader = DataLoader(datasets_train_test['train'], shuffle=True, batch_size=4)\n",
    "eval_dataloader = DataLoader(datasets_train_test['test'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 240\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "# fine-tuning BART\n",
    "optimizer = AdamW(model.parameters() , lr=5e-5)\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0f112fa03740b7a798bb9f6250d7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple ft BART\n",
    "model.save_pretrained(os.getcwd()+'/models/ft_BART_news_summarize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FT and PT comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "model_ft = BartForConditionalGeneration.from_pretrained(os.getcwd() + '/models/ft_BART_news_summarize')\n",
    "summarization_pipeline_ft = pipeline(\"summarization\", model_ft, tokenizer=tokenizer)\n",
    "\n",
    "model_base = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "summarization_pipeline_base = pipeline(\"summarization\", model_base, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6841ec48bc21452595f3d66caa55fe21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but you input_length is only 110. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n",
      "Your max_length is set to 128, but you input_length is only 58. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n",
      "Your max_length is set to 128, but you input_length is only 79. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n",
      "Your max_length is set to 128, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 128, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
      "Your max_length is set to 128, but you input_length is only 73. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.23428974441011538, 'rouge2': 0.06759631182667644, 'rougeL': 0.14956918054867135, 'rougeLsum': 0.18574934506428276}\n"
     ]
    }
   ],
   "source": [
    "# {'rouge1': 0.16258091442735179, 'rouge2': 0.040756608170613315, 'rougeL': 0.12557953810045613, 'rougeLsum': 0.1404810811938183} <- max_length = 20\n",
    "# {'rouge1': 0.22725943712723934, 'rouge2': 0.06288716574190041, 'rougeL': 0.14955314802409142, 'rougeLsum': 0.18272286049547903 <- max_length = 100\n",
    "predictions = []\n",
    "ground_truth = df['Summary'].tolist()\n",
    "rouge = evaluate.load('rouge')\n",
    "for e in tqdm(df.iterrows()):\n",
    "    content = e[1]['Content']\n",
    "    content = content[:1024]\n",
    "    summarization = summarization_pipeline_ft(content , min_length=5)[0]['summary_text']\n",
    "    predictions.append(summarization)\n",
    "    \n",
    "results = rouge.compute(predictions=predictions,references=ground_truth)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668a1ec8e4c44c5b874faabaaee6d626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but you input_length is only 110. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n",
      "Your max_length is set to 128, but you input_length is only 58. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n",
      "Your max_length is set to 128, but you input_length is only 79. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n",
      "Your max_length is set to 128, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 128, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
      "Your max_length is set to 128, but you input_length is only 73. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2968307730250321, 'rouge2': 0.11381039251022732, 'rougeL': 0.1846079764801058, 'rougeLsum': 0.23170666052950833}\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "ground_truth = df['Summary'].tolist()\n",
    "rouge = evaluate.load('rouge')\n",
    "for e in tqdm(df.iterrows()):\n",
    "    content = e[1]['Content']\n",
    "    content = content[:1024]\n",
    "    summarization = summarization_pipeline_base(content , min_length=5)[0]['summary_text']\n",
    "    predictions.append(summarization)\n",
    "    \n",
    "results = rouge.compute(predictions=predictions,references=ground_truth)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import HingeEmbeddingLoss\n",
    "loss_fn = HingeEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "# fine-tuning BART\n",
    "optimizer = AdamW(model.parameters() , lr=5e-5)\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
