{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/gke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/gke/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/gke/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn import preprocessing\n",
    "from torch import nn\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Tweets.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9087\n",
       "neutral     3067\n",
       "positive    2298\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('airline_sentiment')['text'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = df.groupby('airline_sentiment')['text'].nunique().sort_values(ascending=False).reset_index(drop=True)\n",
    "group = []\n",
    "values = []\n",
    "for k,v in df_iter.items():\n",
    "    group.append(k)\n",
    "    values.append(v)\n",
    "df_nunique = pd.DataFrame({'group' : group , 'values':values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(\n",
    "    x=\"group\", \n",
    "    y=\"values\", \n",
    "    data=df_nunique, \n",
    "    estimator=sum, \n",
    "    ci=None, \n",
    "    color='#69b3a2'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# since these are tweets, remove the @s to the airline and other users\n",
    "def remove_statics(text):\n",
    "    text = re.sub('@([A-Za-z0-9a_]+)', '' , text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    text = str(text)\n",
    "    return text.translate(str.maketrans('' , '' , string.punctuation)).lower()\n",
    "\n",
    "def remove_non_alnum(text):\n",
    "    text = str(text)\n",
    "    text_list = [ch for ch in text.split() if ch.isalnum()]\n",
    "    return ' '.join(text_list)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.split()\n",
    "    return ' '.join([e for e in text if e not in stop_words])\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatized_text = []\n",
    "    for word in text.split():\n",
    "        lemmatized_text.append(lemmatizer.lemmatize(word))\n",
    "    return ' '.join(lemmatized_text)\n",
    "\n",
    "def pos_tag(tokenized_text):\n",
    "    tokenized_text = tokenized_text.split()\n",
    "    return nltk.pos_tag(tokenized_text)\n",
    "\n",
    "def tokenize_text(inputString):\n",
    "    if type(inputString) is pd.Series:\n",
    "        df_u = pd.DataFrame(inputString)\n",
    "    else:\n",
    "        df_u = pd.DataFrame([{'preprocessed_text':inputString}])\n",
    "    max_features = 5000\n",
    "    oov = 'OOV'\n",
    "    tokenizer = Tokenizer(num_words = max_features , oov_token = oov)\n",
    "    tokenizer.fit_on_texts(df_u['preprocessed_text'])\n",
    "    tokenized = tokenizer.texts_to_sequences(df_u['preprocessed_text'])\n",
    "    return tokenized , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>text_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>what said</td>\n",
       "      <td>[(@VirginAmerica, VB), (What, WP), (@dhepburn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>plus youve added commercial to the experience ...</td>\n",
       "      <td>[(@VirginAmerica, JJ), (plus, CC), (you've, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>i didnt today must mean i need to take another...</td>\n",
       "      <td>[(@VirginAmerica, NN), (I, PRP), (didn't, VBP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>its really aggressive to blast obnoxious enter...</td>\n",
       "      <td>[(@VirginAmerica, NN), (it's, NN), (really, RB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[(@VirginAmerica, NN), (and, CC), (it's, VB), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)   \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0                                          what said   \n",
       "1  plus youve added commercial to the experience ...   \n",
       "2  i didnt today must mean i need to take another...   \n",
       "3  its really aggressive to blast obnoxious enter...   \n",
       "4            and its a really big bad thing about it   \n",
       "\n",
       "                                            text_pos  \n",
       "0  [(@VirginAmerica, VB), (What, WP), (@dhepburn,...  \n",
       "1  [(@VirginAmerica, JJ), (plus, CC), (you've, NN...  \n",
       "2  [(@VirginAmerica, NN), (I, PRP), (didn't, VBP)...  \n",
       "3  [(@VirginAmerica, NN), (it's, NN), (really, RB...  \n",
       "4  [(@VirginAmerica, NN), (and, CC), (it's, VB), ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_text'] = df['text'].apply(remove_stopwords)\n",
    "df['preprocessed_text'] = df['text'].apply(remove_statics)\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(lemmatize)\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply((remove_punctuations))\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(remove_non_alnum)\n",
    "df['text_pos'] = df['text'].apply(pos_tag)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "labels = df['airline_sentiment'].unique()\n",
    "le = preprocessing.LabelEncoder()\n",
    "encoded_labels = le.fit(labels)\n",
    "article_category_le = le.transform(df['airline_sentiment'])\n",
    "print(encoded_labels.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_x , tokenizer = tokenize_text(df['preprocessed_text'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "MAX_LEN = 5000\n",
    "Xtrain = pad_sequences(tokenized_x , maxlen=MAX_LEN)\n",
    "X_train , X_test , y_train , y_test = train_test_split(Xtrain , article_category_le , test_size = 0.20 , random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2928, 5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 5000)]            0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 5000, 64)          320000    \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 4998, 128)         24704     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 639744)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1919235   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,263,939\n",
      "Trainable params: 2,263,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sequence_length = X_train.shape[1]\n",
    "vocab_size = 5000\n",
    "filter_sizes = [3 , 4 , 5]\n",
    "num_filters = 128\n",
    "drop = 0.50\n",
    "epochs = 5\n",
    "embed_dim = 64\n",
    "\n",
    "num_of_classes = len(le.classes_)\n",
    "input = tf.keras.layers.Input(shape = (sequence_length ,))\n",
    "embedding = tf.keras.layers.Embedding(sequence_length, embed_dim)(input)\n",
    "conv1 = tf.keras.layers.Conv1D(num_filters , kernel_size = (filter_sizes[0]) , padding='valid',activation='relu')(embedding)\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "output = tf.keras.layers.Dense(num_of_classes)(flatten)\n",
    "\n",
    "model = tf.keras.models.Model(input , output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 21:12:37.336256: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 52s 281ms/step - loss: 1.1460 - accuracy: 0.6218 - val_loss: 1.0986 - val_accuracy: 0.6349\n",
      "Epoch 2/5\n",
      "183/183 [==============================] - 56s 306ms/step - loss: 1.0986 - accuracy: 0.6249 - val_loss: 1.0986 - val_accuracy: 0.6349\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - 59s 324ms/step - loss: 1.0986 - accuracy: 0.6249 - val_loss: 1.0986 - val_accuracy: 0.6349\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - 60s 330ms/step - loss: 1.0986 - accuracy: 0.6249 - val_loss: 1.0986 - val_accuracy: 0.6349\n",
      "Epoch 5/5\n",
      "183/183 [==============================] - 66s 359ms/step - loss: 1.0986 - accuracy: 0.6249 - val_loss: 1.0986 - val_accuracy: 0.6349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d390460>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train , batch_size=64 , epochs = 5, verbose=1 , validation_data=(X_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('kosig': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66761006ad8bd18f178cbe8c4411e89165011137b898da0879d8d636d9cdd01e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
